---
title: OpenAI API
description: A step-by-step guide on how to integrate Jan with Azure OpenAI.
keywords:
  [
    Jan,
    Customizable Intelligence, LLM,
    local AI,
    privacy focus,
    free and open source,
    private and offline,
    conversational AI,
    no-subscription fee,
    large language models,
    integration,
    Azure OpenAI Service,
  ]
---

import { Callout, Steps } from 'nextra/components'



# OpenAI API

## How to Integrate OpenAI API with Jan
This guide provides step-by-step instructions on integrating the OpenAI API with Jan, enabling users to leverage OpenAI's capabilities within Jan's conversational interface.

## Integration Steps
<Steps>
### Step 1: Configure OpenAI API Keys
1. Obtain OpenAI API keys from your [OpenAI Platform](https://platform.openai.com/api-keys) dashboard.
2. Copy your OpenAI Key and the endpoint URL you want to use.
3. Navigate to the **Jan app** > **Settings**.
4. Select the **OpenAI Inference Engine**.
5. Insert the **API Key** and the **endpoint URL** into their respective fields.

<Callout type='info' emoji=''>
  - You can also manually edit the JSON file in `~/jan/settings/@janhq`.
</Callout>

### Step 2: Select Model

1. Navigate to the **Hub** section.
2. Ensure that you have downloaded the OpenAI model you want to use.

<Callout type='info' emoji=''>
  - The OpenAI Inference Engine is the default extension for the Jan application. All OpenAI models should be installed automatically when you install Jan application.
</Callout>

### Step 3: Start the Model

1. Navigate to the **Thread** section.
2. Under the **Model** section, select the OpenAI model you want to use.
3. Start the conversation with the OpenAI model.
</Steps>
### `model.json`

You can also settings the OpenAI models as you desired. By customizing the `model.json` file.

<Callout type='info' emoji=''>
- If you've set up your model's configuration in `nitro.json`, please note that `model.json` can overwrite the settings.
- When using OpenAI models like GPT-3.5 and GPT-4, you can use the default settings in `model.json` file.
</Callout>

There are two important fields in `model.json` that you need to setup:

#### Settings

This is the field where to set your engine configurations, there are two imporant field that you need to define for your local models:

| Term              | Description                                                           |
| ----------------- | --------------------------------------------------------------------- |
| `ctx_len`         | Defined based on the model's context size.                            |
| `prompt_template` | Defined based on the model's trained template (e.g., ChatML, Alpaca). |

To set up the `prompt_template` based on your model, follow the steps below: 1. Visit [Hugging Face](https://huggingface.co/), an open-source machine learning platform. 2. Find the current model that you're using (e.g., [Gemma 7b it](https://huggingface.co/google/gemma-7b-it)). 3. Review the text and identify the template.

#### Parameters

`parameters` is the adjustable settings that affect how your model operates or processes the data.
The fields in `parameters` are typically general and can be the same across models. An example is provided below:

```json
"parameters":{
  "temperature": 0.7,
  "top_p": 0.95,
  "stream": true,
  "max_tokens": 4096,
  "frequency_penalty": 0,
  "presence_penalty": 0
}
```

<Callout type='info' emoji=''>
- You can find the list of available models in the [OpenAI Platform](https://platform.openai.com/docs/models/overview).
- The `id` property needs to match the model name in the list.
  - For example, if you want to use the [GPT-4 Turbo](https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo), you must set the `id` property to `gpt-4-1106-preview`.
</Callout>

## Troubleshooting

If you encounter any issues during the integration process or while using OpenAI with Jan, consider the following troubleshooting steps:

- Double-check your API credentials and ensure they are correctly entered.
- Check for any error messages or logs that may provide insight into the issue.
- Reach out to OpenAI API support for assistance if needed.