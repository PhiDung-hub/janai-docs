---
title: Mac - Metal
description: Metal GPU support on Jan for llama.cpp
keywords:
  [
    Jan,
    Customizable Intelligence, LLM,
    local AI,
    privacy focus,
    free and open source,
    private and offline,
    conversational AI,
    no-subscription fee,
    large language models,
    Llama CPP integration,
    llama.cpp Extension,
    Intel CPU,
    AMD CPU,
    NVIDIA GPU,
    AMD GPU Radeon,
    Apple Silicon,
    Intel Arc GPU,
  ]
---

# Mac Metal GPU
- Jan with `llama.cpp` as default supported inference engine on Mac Silicon is enabled to run with `Metal 3` by default. Mac Intel currently does not support it.
- Users need to have MacOS Ventura or beyond in order to use.
- As Mac Silicon uses `unified memory`, the performance gain is great