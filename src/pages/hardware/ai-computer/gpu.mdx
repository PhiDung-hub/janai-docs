---
title: GPU
description: A step-by-step guide on integrating Jan with a Discord bot.
keywords:
  [
    Jan,
    Customizable Intelligence, LLM,
    local AI,
    privacy focus,
    free and open source,
    private and offline,
    conversational AI,
    no-subscription fee,
    large language models,
    Discord integration,
    Discord,
    bot,
  ]
---
import { Callout, Steps, Tabs } from 'nextra/components'
import { Cards, Card } from 'nextra/components'

<Callout type="info">
This page is still under construction.
</Callout>

## GPU Setup
<Tabs items = {[ 'NVIDIA', 'Mac', 'AMD', 'Intel']}>
    <Tabs.Tab>

        # NVIDIA GPU

        Jan supports NVIDIA GPUs exclusively on Windows and Linux through its Desktop app. The default local AI inference engine, `llama.cpp`, has a CUBLAS backend.
        ## Pre-requisites
        To use NVIDIA GPU, you must have a compatible NVIDIA GPU and the latest NVIDIA driver installed.
        ### NVIDIA Driver

        - Install an [NVIDIA Driver](https://www.nvidia.com/Download/index.aspx) supporting CUDA 11.7 or higher.
        - Use the following command to verify the installation:

        ```bash
        nvidia-smi
        ```

        ### CUDA Toolkit

        - Install a [CUDA toolkit](https://developer.nvidia.com/cuda-downloads) that is compatible with your NVIDIA driver.
        - Use the following command to verify the installation:

        ```bash
        nvcc --version
        ```
        ### Linux Specifics

        - Ensure that `gcc-11`, `g++-11`, `cpp-11`, or higher is installed. To install, please see [here](https://gcc.gnu.org/projects/cxx-status.html#cxx17) for Ubuntu installation.

        - **Post-Installation Actions**: Add CUDA libraries to `LD_LIBRARY_PATH`. To install, follow the [Post-installation Actions](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#post-installation-actions) instructions.

        ### Validated NVIDIA Cards
        The following NVIDIA cards are confirmed to work:

        | NVIDIA GPU      |
        |--------------------------|
        | GeForce RTX 40 Series    |
        | GeForce RTX 30 Series    |
        | GeForce RTX 20 Series    |
        | GeForce GTX Series       |
        | NVIDIA Titan Series      |
        | NVIDIA Quadro Series     |
        | NVIDIA Tesla Series (Server GPUs) |
    </Tabs.Tab>
    <Tabs.Tab>

        # Mac Metal GPU
        Jan is optimized for Mac Silicon, utilizing `llama.cpp` as its default supported inference engine and leveraging `Metal 3` by default.
        <Callout type='info'>
        This setup is not supported on Mac Intel.
        </Callout>

        ## Pre-requisites
        To utilize Jan on Mac Silicon, users must have:
        - macOS Ventura or later versions

        <Callout type='info'>
        The use of `unified memory` in Mac Silicon significantly enhances performance, providing substantial performance gains.
        </Callout>
    </Tabs.Tab>
    <Tabs.Tab>

       # AMD GPU

        Jan is designed to support AMD GPUs on Windows and Linux through its Desktop app. The default inference engine for local AI is `llama.cpp`, utilizes a Vulkan backend to ensure compatibility with AMD GPUs.

        ## Pre-requisites
        - You do not need to install additional drivers or software for AMD GPU as it's supported by default with Vulkan.
        - The following AMD Radeon cards are confirmed to work:

        | AMD GPU                |
        |-----------------------|
        | Radeon RX Vega series |
        | Radeon RX 7000 series |
        | Radeon RX 6000 series |
        | Radeon RX 5000 series |
        | Radeon Pro series     |
        | Radeon 600 series     |
        | Radeon 500 series     |
        | Radeon 400 series     |
        | Radeon 300 series     |
        | Radeon 200 series     |

        <Callout type='info'>
        You can find more information about AMD GPUs, such as dGPUs [here](https://en.wikipedia.org/wiki/Category:AMD_graphics_cards).
        </Callout>
    </Tabs.Tab>
    <Tabs.Tab>

       # Intel Arc GPU

        Jan supports Intel Arc on Windows and Linux via its Desktop app, functioning similarly to its AMD GPU support. The default local AI inference engine, `llama.cpp`, uses a Vulkan backend.

        ## Pre-requisites
        You do not need to install additional drivers or software for Intel Arc GPU as it's supported by default with Vulkan.

        <Callout type='info'>
        You can find more information about Intel Arc GPU for Desktop/ Laptop as dGPU [here](https://www.intel.com/content/www/us/en/products/details/discrete-gpus/arc.html)
        </Callout>
    </Tabs.Tab>
</Tabs>
