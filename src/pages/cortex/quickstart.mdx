---
title: Quickstart
description: Cortex Quickstart.
keywords:
  [
    Jan,
    Customizable Intelligence, LLM,
    local AI,
    privacy focus,
    free and open source,
    private and offline,
    conversational AI,
    no-subscription fee,
    large language models,
    Cortex,
    Jan,
    LLMs
  ]
---

import { Callout, Steps } from 'nextra/components'
import { Cards, Card } from 'nextra/components'

# Quickstart

<Callout type="warning">
ðŸš§ Cortex is under construction.
</Callout>

```bash
# 1. Install the NPM package
# (Once installed, Cortex automatically identifies your CPU and GPU and installs the necessary dependencies)
npm i -g @janhq/cortex

# 2. Download a GGUF model from Hugging Face
#    Models save to $(npm list -g)/node_modules
cortex models pull janhq/TinyLlama-1.1B-Chat-v1.0-GGUF

# 3. Load the model
cortex models start janhq/TinyLlama-1.1B-Chat-v1.0-GGUF

# 4. Start chatting with the model
cortex chat 
```

You can also run Cortex in server mode
```bash
cortex serve
```

Thatâ€™s it! 

## What's Next?
With Cortex now fully operational, you're ready to delve deeper:
- Explore how to [install Cortex](/cortex/installation) across various hardware environments.
- Familiarize yourself with the comprehensive set of [Cortex CLI commands](/cortex/cli) available for use.
- Gain insights into the systemâ€™s design by examining the [architecture](/cortex/architecture) of Cortex.