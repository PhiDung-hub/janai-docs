---
title: Cortex Pull
description: Cortex CLI.
keywords:
  [
    Jan,
    Customizable Intelligence, LLM,
    local AI,
    privacy focus,
    free and open source,
    private and offline,
    conversational AI,
    no-subscription fee,
    large language models,
    Cortex,
    Jan,
    LLMs
  ]
---

import { Callout, Steps } from 'nextra/components'
import { Cards, Card } from 'nextra/components'

<Callout type="warning">
ðŸš§ Cortex is under construction.
</Callout>

# `cortex pull`

This command facilitates downloading machine learning models from various model hubs, including the popular ðŸ¤— [Hugging Face](https://huggingface.co/).

By default, models are downloaded to the `node_modules library path. For additional information on storage paths and options, refer [here](/cortex/cli#storage).

## Alias
The following alias is also available for downloading models:
- `cortex download _`

## Usage

### Preconfigured Models

Reconfigured models (with optimal runtime parameters and templates) are available from the [Jan Model Hub](https://huggingface.co/janhq) on Hugging Face.

Models can be downloaded using a Docker-like interface with the following syntax: `repo_name:branch`. Each variant may include different quantizations and sizes, typically organized in the repositoryâ€™s branches.

The following models are available via repos: 
- `llama3`: https://huggingface.co/janhq/llama3
- `mistral`: https://huggingface.co/janhq/mistral
- `tinyllama`: https://huggingface.co/janhq/tinyllama

<Callout type="info">
New models will soon be added to HuggingFace's janhq repository.
</Callout>

```bash
# Pull a model most compatible with your hardware
cortex pull llama3

# Download a specific variant with `repo_name:branch`
cortex pull llama3:7b
```

### Hugging Face Models

You can download any GGUF, TensorRT, or supported-format model directly from Hugging Face.

```bash
# cortex pull HF_MODEL_ID
cortex pull microsoft/Phi-3-mini-4k-instruct-gguf
```

### Managing Models

The `models` subcommand allows for managing models. To view the available options, run:

```
cortex models -h
```

To use:

```
Usage: cortex models [options] [command]

Subcommands for managing models

Options:
  -h, --help     display help for command

Commands:
  pull|download  Download a model. Working with HuggingFace model id.
                 Example: cortex models pull <model_id>

  list           List all models locally.
                 Example: cortex models list
  
  get            Get a model by ID.
                 Example: cortex models get <model_id>

  start          Start a model by ID.
                 Example: cortex models start <model_id>

  stop           Stop a model by ID.
                 Example: cortex models stop <model_id>

  remove         Remove a model by ID locally.
                 Example: cortex models remove <model_id>
```
