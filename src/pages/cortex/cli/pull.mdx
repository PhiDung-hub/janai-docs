---
title: Cortex Pull
description: Cortex CLI.
keywords:
  [
    Jan,
    Customizable Intelligence, LLM,
    local AI,
    privacy focus,
    free and open source,
    private and offline,
    conversational AI,
    no-subscription fee,
    large language models,
    Cortex,
    Jan,
    LLMs
  ]
---

import { Callout, Steps } from 'nextra/components'
import { Cards, Card } from 'nextra/components'

<Callout type="warning">
ðŸš§ Cortex is under construction.
</Callout>

# `cortex pull`

This command facilitates downloading machine learning models from various model hubs, including the popular ðŸ¤— [Hugging Face](https://huggingface.co/).

By default, models are downloaded to the `node_modules library path. For additional information on storage paths and options, refer [here](/cortex/cli#storage).

<Callout type="info">
This command is compatible with all OpenAI and OpenAI-compatible endpoints.
</Callout>

## Alias
The following alias is also available for downloading models:
- `cortex download _`

## Usage

### Preconfigured Models

Reconfigured models (with optimal runtime parameters and templates) are available from the [Jan Model Hub](https://huggingface.co/janhq) on Hugging Face.

Models can be downloaded using a Docker-like interface with the following syntax: `repo_name:branch`. Each variant may include different quantizations and sizes, typically organized in the repositoryâ€™s branches.

The following models are available via repos: 
- `llama3`: https://huggingface.co/janhq/llama3
- `mistral`: https://huggingface.co/janhq/mistral
- `tinyllama`: https://huggingface.co/janhq/tinyllama

<Callout type="info">
New models will soon be added to HuggingFace's janhq repository.
</Callout>

```bash
# Pull a model most compatible with your hardware
cortex pull llama3

# Pull a specific variant with `repo_name:branch`
cortex pull llama3:7b
```

### Hugging Face Models

You can download any GGUF, TensorRT, or supported-format model directly from Hugging Face.

```bash
# cortex pull HF_MODEL_ID
cortex pull microsoft/Phi-3-mini-4k-instruct-gguf
```

## Options

```
  -h, --help     display help for command
```
